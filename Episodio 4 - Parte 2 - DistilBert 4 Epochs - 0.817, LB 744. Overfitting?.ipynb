{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66fdded",
   "metadata": {},
   "source": [
    "# ðŸ¤— Transformers Episodio 4 - Parte 2\n",
    "\n",
    "Distill Bert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b7e8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import get_submission, submit, get_tokenizer_and_model,\\\n",
    "                  compute_metrics, load_dfs, tokenize, get_train_args\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "transformers.logging.set_verbosity_warning()\n",
    "\n",
    "def read_scores():\n",
    "    s = !kaggle competitions submissions nlp-getting-started \n",
    "    df = pd.DataFrame([(l.split()[0], l.split()[-2]) for l in s[2:]], columns=[\"Archivo\", \"Score\"]).set_index(\"Archivo\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "utils.nb_set_width()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd02996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"episodio_4_pred_2\"\n",
    "pred_file_name = \"episodio_4_pred_2.csv\"\n",
    "submit_message = \"Episodio 4 Prediccion 2 Distill Bert\"\n",
    "\n",
    "model_name = \"distilbert-base-cased\"\n",
    "tokenizer, model = get_tokenizer_and_model(model_name)\n",
    "\n",
    "df_base, df_test = load_dfs()\n",
    "df_train, df_val = train_test_split(df_base, test_size=0.066)\n",
    "ds_train, ds_val, ds_test = tokenize(tokenizer, df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d001dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7110, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8a0b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(503, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a026b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "#del model\n",
    "#del trainer\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597b6c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3556' max='3556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3556/3556 27:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.511600</td>\n",
       "      <td>0.420952</td>\n",
       "      <td>0.831014</td>\n",
       "      <td>0.788030</td>\n",
       "      <td>0.863388</td>\n",
       "      <td>0.724771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.371700</td>\n",
       "      <td>0.470815</td>\n",
       "      <td>0.838966</td>\n",
       "      <td>0.801956</td>\n",
       "      <td>0.858639</td>\n",
       "      <td>0.752294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.258100</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.834990</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.761468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.834143</td>\n",
       "      <td>0.811133</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.775785</td>\n",
       "      <td>0.793578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='408' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [408/408 00:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=get_train_args(model_id, epochs=4), \n",
    "                  train_dataset=ds_train, \n",
    "                  eval_dataset=ds_val,\n",
    "                  compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "df_res = get_submission(trainer, ds_test, pred_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55a9351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdout=\n",
      "Successfully submitted to Natural Language Processing with Disaster Tweets\n",
      "stderr=\n",
      "\r",
      "  0%|          | 0.00/22.2k [00:00<?, ?B/s]\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.2k/22.2k [00:00<00:00, 122kB/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submit(pred_file_name, \"Distil Bert 4 epochs - Overfitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89f3504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archivo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_2.csv</th>\n",
       "      <td>0.81734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_1.csv</th>\n",
       "      <td>0.81274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_first_submission.csv</th>\n",
       "      <td>0.80049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Score\n",
       "Archivo                           \n",
       "episodio_4_pred_2.csv      0.81734\n",
       "episodio_4_pred_1.csv      0.81274\n",
       "bert_first_submission.csv  0.80049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Leaderbord - 744\n",
    "read_scores();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ba517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f103303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28\r\n",
      "drwxr-xr-x 2 dataista dataista 4096 Jun 17 23:50 checkpoint-1000\r\n",
      "drwxr-xr-x 2 dataista dataista 4096 Jun 17 23:55 checkpoint-1500\r\n",
      "drwxr-xr-x 2 dataista dataista 4096 Jun 17 23:59 checkpoint-2000\r\n",
      "drwxr-xr-x 2 dataista dataista 4096 Jun 18 00:03 checkpoint-2500\r\n",
      "drwxr-xr-x 2 dataista dataista 4096 Jun 18 00:07 checkpoint-3000\r\n",
      "drwxr-xr-x 2 dataista dataista 4096 Jun 18 00:10 checkpoint-3500\r\n",
      "drwxr-xr-x 2 dataista dataista 4096 Jun 17 23:46 checkpoint-500\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22a1b83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7110"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un step es un batch\n",
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0697e901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steps por epoch\n",
    "3556 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0743541e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7112.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steps por epoch (889) por batch size (8) son la cantidad de samples (OK!)\n",
    "889.0 * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eec7c6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1778.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entonces, 2 epocs es 1778 steps, vamos a cargar ese checkpoint\n",
    "889.0 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56a36604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_debug()\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34695a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-1500/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.7.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-1500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-1500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 503\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4690554141998291,\n",
       " 'eval_accuracy': 0.827037773359841,\n",
       " 'eval_f1': 0.7913669064748201,\n",
       " 'eval_precision': 0.8291457286432161,\n",
       " 'eval_recall': 0.7568807339449541,\n",
       " 'eval_runtime': 7.7057,\n",
       " 'eval_samples_per_second': 65.277,\n",
       " 'eval_steps_per_second': 8.176}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cp = \"/home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-1500\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(cp, num_labels=2)\n",
    "\n",
    "trainer = Trainer(model=model, args=get_train_args(\"test\", epochs=2), \n",
    "                  train_dataset=ds_train, \n",
    "                  eval_dataset=ds_val,\n",
    "                  compute_metrics=compute_metrics)\n",
    "\n",
    "#trainer.train()\n",
    "\n",
    "#df_res = get_submission(trainer, ds_test, pred_file_name)\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b448e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-2000/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.7.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-2000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-2000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 503\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6379884481430054,\n",
       " 'eval_accuracy': 0.8250497017892644,\n",
       " 'eval_f1': 0.8026905829596411,\n",
       " 'eval_precision': 0.7850877192982456,\n",
       " 'eval_recall': 0.8211009174311926,\n",
       " 'eval_runtime': 7.7217,\n",
       " 'eval_samples_per_second': 65.141,\n",
       " 'eval_steps_per_second': 8.159}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = \"/home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-2000\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(cp, num_labels=2)\n",
    "\n",
    "trainer = Trainer(model=model, args=get_train_args(\"test\", epochs=2), \n",
    "                  train_dataset=ds_train, \n",
    "                  eval_dataset=ds_val,\n",
    "                  compute_metrics=compute_metrics)\n",
    "\n",
    "#trainer.train()\n",
    "\n",
    "#df_res = get_submission(trainer, ds_test, pred_file_name)\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26a5e46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-2000/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.7.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-2000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at /home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-2000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 503\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 01:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6379884481430054,\n",
       " 'eval_accuracy': 0.8250497017892644,\n",
       " 'eval_f1': 0.8026905829596411,\n",
       " 'eval_precision': 0.7850877192982456,\n",
       " 'eval_recall': 0.8211009174311926,\n",
       " 'eval_runtime': 7.9908,\n",
       " 'eval_samples_per_second': 62.947,\n",
       " 'eval_steps_per_second': 7.884}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = \"/home/dataista/git/twitch-streams/data/models/episodio_4_pred_2/checkpoint-2000\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(cp, num_labels=2)\n",
    "\n",
    "trainer = Trainer(model=model, args=get_train_args(\"test\", epochs=2), \n",
    "                  train_dataset=ds_train, \n",
    "                  eval_dataset=ds_val,\n",
    "                  compute_metrics=compute_metrics)\n",
    "\n",
    "#trainer.train()\n",
    "\n",
    "#df_res = get_submission(trainer, ds_test, pred_file_name)\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba66dcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 3263\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_submission(trainer, ds_test, file_name=\"episodio_4_pred_2_checkpoint_2000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f2de28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdout=\n",
      "Successfully submitted to Natural Language Processing with Disaster Tweets\n",
      "stderr=\n",
      "\r",
      "  0%|          | 0.00/22.2k [00:00<?, ?B/s]\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.2k/22.2k [00:00<00:00, 115kB/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submit(\"episodio_4_pred_2_checkpoint_2000.csv\", \"Checkpoint 2000 de DistilBert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11f42f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archivo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_2_checkpoint_2000.csv</th>\n",
       "      <td>0.80968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_2.csv</th>\n",
       "      <td>0.81734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_1.csv</th>\n",
       "      <td>0.81274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_first_submission.csv</th>\n",
       "      <td>0.80049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Score\n",
       "Archivo                                       \n",
       "episodio_4_pred_2_checkpoint_2000.csv  0.80968\n",
       "episodio_4_pred_2.csv                  0.81734\n",
       "episodio_4_pred_1.csv                  0.81274\n",
       "bert_first_submission.csv              0.80049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_scores();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b5f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66fdded",
   "metadata": {},
   "source": [
    "# ðŸ¤— Episodio 5 - RoBERTa V2 - 3 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b7e8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import get_submission, submit, get_tokenizer_and_model,\\\n",
    "                  compute_metrics, load_dfs, tokenize, get_train_args\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "transformers.logging.set_verbosity_warning()\n",
    "\n",
    "def read_scores():\n",
    "    s = !kaggle competitions submissions nlp-getting-started \n",
    "    df = pd.DataFrame([(l.split()[0], l.split()[-2]) for l in s[2:]], columns=[\"Archivo\", \"Score\"]).set_index(\"Archivo\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "utils.nb_set_width()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd02996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"episodio_5_v2\"\n",
    "pred_file_name = f\"{model_id}.csv\"\n",
    "submit_message = \"Episodio 5 RoBERTa Base 3 epochs\"\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer, model = get_tokenizer_and_model(model_name)\n",
    "\n",
    "df_base, df_test = load_dfs()\n",
    "df_train, df_val = train_test_split(df_base, test_size=0.066)\n",
    "ds_train, ds_val, ds_test = tokenize(tokenizer, df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597b6c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2667' max='2667' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2667/2667 39:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.486917</td>\n",
       "      <td>0.771372</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.906780</td>\n",
       "      <td>0.507109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.557595</td>\n",
       "      <td>0.761431</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.502370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.601300</td>\n",
       "      <td>0.630170</td>\n",
       "      <td>0.636183</td>\n",
       "      <td>0.687179</td>\n",
       "      <td>0.537433</td>\n",
       "      <td>0.952607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.601300</td>\n",
       "      <td>0.446269</td>\n",
       "      <td>0.838966</td>\n",
       "      <td>0.798005</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.758294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>0.489709</td>\n",
       "      <td>0.836978</td>\n",
       "      <td>0.797030</td>\n",
       "      <td>0.834197</td>\n",
       "      <td>0.763033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>0.513146</td>\n",
       "      <td>0.795229</td>\n",
       "      <td>0.778495</td>\n",
       "      <td>0.712598</td>\n",
       "      <td>0.857820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>0.483765</td>\n",
       "      <td>0.829026</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.807882</td>\n",
       "      <td>0.777251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.439466</td>\n",
       "      <td>0.821074</td>\n",
       "      <td>0.784689</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.777251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.444494</td>\n",
       "      <td>0.811133</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.853081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.409108</td>\n",
       "      <td>0.852883</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.844221</td>\n",
       "      <td>0.796209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.399879</td>\n",
       "      <td>0.856859</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.852792</td>\n",
       "      <td>0.796209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.394601</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.824940</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.815166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>0.411872</td>\n",
       "      <td>0.854871</td>\n",
       "      <td>0.822384</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.800948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2667, training_loss=0.5155977607443845, metrics={'train_runtime': 2351.3276, 'train_samples_per_second': 9.071, 'train_steps_per_second': 1.134, 'total_flos': 8167600546099200.0, 'train_loss': 0.5155977607443845, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=get_train_args(model_id, epochs=3, save_steps=500, evaluation_strategy=\"steps\", \n",
    "                                                   eval_steps=200), \n",
    "                  train_dataset=ds_train, \n",
    "                  eval_dataset=ds_val,\n",
    "                  compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d0dce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='408' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [408/408 01:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_res = get_submission(trainer, ds_test, pred_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1073c13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdout=\n",
      "Successfully submitted to Natural Language Processing with Disaster Tweets\n",
      "stderr=\n",
      "\r",
      "  0%|          | 0.00/22.2k [00:00<?, ?B/s]\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.2k/22.2k [00:00<00:00, 113kB/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submit(pred_file_name, submit_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b271055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archivo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>episodio_5_v2.csv</th>\n",
       "      <td>0.82807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_5_part1-4-epochs-cp2500.csv</th>\n",
       "      <td>0.82592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_5_part1-4-epochs.csv</th>\n",
       "      <td>0.81918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_5_part1.csv</th>\n",
       "      <td>0.82562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_5.csv</th>\n",
       "      <td>0.57033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_4.csv</th>\n",
       "      <td>0.81979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_2_checkpoint_2000.csv</th>\n",
       "      <td>0.80968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_2.csv</th>\n",
       "      <td>0.81734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episodio_4_pred_1.csv</th>\n",
       "      <td>0.81274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_first_submission.csv</th>\n",
       "      <td>0.80049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Score\n",
       "Archivo                                       \n",
       "episodio_5_v2.csv                      0.82807\n",
       "episodio_5_part1-4-epochs-cp2500.csv   0.82592\n",
       "episodio_5_part1-4-epochs.csv          0.81918\n",
       "episodio_5_part1.csv                   0.82562\n",
       "episodio_5.csv                         0.57033\n",
       "episodio_4_pred_4.csv                  0.81979\n",
       "episodio_4_pred_2_checkpoint_2000.csv  0.80968\n",
       "episodio_4_pred_2.csv                  0.81734\n",
       "episodio_4_pred_1.csv                  0.81274\n",
       "bert_first_submission.csv              0.80049"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Leaderbord - 625 - 0.82562\n",
    "read_scores();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a37584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "625 - 576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a71fee6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "576 - 141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f397583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22153846153846155"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "576 / 2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a954b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830b5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
